{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3286e21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "#  '/media/melissa/EXTERNAL_USB/DocRED'\n",
    "from collections import Counter\n",
    "docred_path='/media/melissa/EXTERNAL_USB/DocRED'\n",
    "redocred_path='/media/melissa/EXTERNAL_USB/Re-DocRED'\n",
    "def load_dataset(path):\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d362b9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "na_label = \"Na\"\n",
    "test_label=\"P17\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eb897740",
   "metadata": {},
   "outputs": [],
   "source": [
    "docred = load_dataset('/media/melissa/EXTERNAL_USB/DocRED/train_distant.json')\n",
    "word2id = load_dataset('/media/melissa/EXTERNAL_USB/DocRED/DocRED_baseline_metadata/word2id.json')\n",
    "redocred = load_dataset('/media/melissa/EXTERNAL_USB/Re-DocRED/data/train_revised.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c1a97523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101873"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5b37a17c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3053"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(redocred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d0750d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total relations: 38180\n",
      "NA-labeled relations: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for NA labels\n",
    "na_count = 0\n",
    "total_relations = 0\n",
    "\n",
    "for sample in docred:\n",
    "    for label in sample['labels']:\n",
    "        total_relations += 1\n",
    "        if label['r'] == 'Na':\n",
    "            na_count += 1\n",
    "\n",
    "print(f\"Total relations: {total_relations}\")\n",
    "print(f\"NA-labeled relations: {na_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca3e1723",
   "metadata": {},
   "outputs": [],
   "source": [
    "rel2id_path ='/media/melissa/EXTERNAL_USB/DocRED/DocRED_baseline_metadata/rel2id.json'\n",
    "with open(rel2id_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    rel2id = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1c05aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'vertexSet', 'sents', 'labels', 'title'}\n"
     ]
    }
   ],
   "source": [
    "all_keys_docred = set()\n",
    "\n",
    "for doc in docred:\n",
    "    all_keys_docred.update(doc.keys())\n",
    "print(all_keys_docred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21cbbfd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'vertexSet', 'sents', 'labels', 'title'}\n"
     ]
    }
   ],
   "source": [
    "all_keys_redocred = set()\n",
    "\n",
    "for re in redocred:\n",
    "    all_keys_redocred.update(re.keys())\n",
    "print(all_keys_redocred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e157a3ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'labels': [{'evidence': [0], 'h': 6, 'r': 'P131', 't': 8},\n",
      "            {'evidence': [0], 'h': 8, 'r': 'P150', 't': 6},\n",
      "            {'evidence': [0], 'h': 8, 'r': 'P150', 't': 5},\n",
      "            {'evidence': [0], 'h': 8, 'r': 'P150', 't': 0},\n",
      "            {'evidence': [0], 'h': 5, 'r': 'P131', 't': 8},\n",
      "            {'evidence': [0], 'h': 0, 'r': 'P131', 't': 8}],\n",
      " 'sents': [['Zigong',\n",
      "            'dialect',\n",
      "            '(',\n",
      "            ')',\n",
      "            'is',\n",
      "            'a',\n",
      "            'branch',\n",
      "            'of',\n",
      "            'Southwestern',\n",
      "            'Mandarin',\n",
      "            ',',\n",
      "            'spoken',\n",
      "            'mainly',\n",
      "            'in',\n",
      "            'Zigong',\n",
      "            ',',\n",
      "            'Fushun',\n",
      "            ',',\n",
      "            'Weiyuan',\n",
      "            ',',\n",
      "            'east',\n",
      "            'Rongxian',\n",
      "            'and',\n",
      "            'some',\n",
      "            'parts',\n",
      "            'of',\n",
      "            'Yibin',\n",
      "            ',',\n",
      "            'Neijiang',\n",
      "            ',',\n",
      "            'Longchang',\n",
      "            'and',\n",
      "            'other',\n",
      "            'neighboring',\n",
      "            'areas',\n",
      "            'of',\n",
      "            'Sichuan',\n",
      "            '.'],\n",
      "           ['At',\n",
      "            'least',\n",
      "            'four',\n",
      "            'Chinese',\n",
      "            'dialects',\n",
      "            'are',\n",
      "            'spoken',\n",
      "            'in',\n",
      "            'Zigong',\n",
      "            'City',\n",
      "            ':',\n",
      "            'Zigong',\n",
      "            'dialect',\n",
      "            ',',\n",
      "            'Rongxian',\n",
      "            'dialect',\n",
      "            ',',\n",
      "            'Hakka',\n",
      "            'and',\n",
      "            'Minjiang',\n",
      "            'dialect',\n",
      "            '.'],\n",
      "           ['A',\n",
      "            'majority',\n",
      "            'of',\n",
      "            'people',\n",
      "            'in',\n",
      "            'Zigong',\n",
      "            'speak',\n",
      "            'Zigong',\n",
      "            'dialect',\n",
      "            '.'],\n",
      "           ['However',\n",
      "            ',',\n",
      "            'most',\n",
      "            'people',\n",
      "            'in',\n",
      "            'Rongxian',\n",
      "            ',',\n",
      "            'a',\n",
      "            'county',\n",
      "            'of',\n",
      "            'Zigong',\n",
      "            'City',\n",
      "            ',',\n",
      "            'speak',\n",
      "            'Rongxian',\n",
      "            'dialect',\n",
      "            ',',\n",
      "            'whose',\n",
      "            'pronunciation',\n",
      "            'is',\n",
      "            'quite',\n",
      "            'different',\n",
      "            'from',\n",
      "            'that',\n",
      "            'of',\n",
      "            'Zigong',\n",
      "            'dialect',\n",
      "            '.'],\n",
      "           ['Besides',\n",
      "            ',',\n",
      "            'owing',\n",
      "            'to',\n",
      "            'a',\n",
      "            'great',\n",
      "            'number',\n",
      "            'of',\n",
      "            'Hakka',\n",
      "            'immigrants',\n",
      "            'in',\n",
      "            'history',\n",
      "            ',',\n",
      "            'a',\n",
      "            'small',\n",
      "            'number',\n",
      "            'of',\n",
      "            'Hakka',\n",
      "            'people',\n",
      "            'in',\n",
      "            'certain',\n",
      "            'towns',\n",
      "            'also',\n",
      "            'remain',\n",
      "            'to',\n",
      "            'speak',\n",
      "            'Hakka',\n",
      "            '.'],\n",
      "           ['Also',\n",
      "            ',',\n",
      "            'Minjiang',\n",
      "            'dialect',\n",
      "            'is',\n",
      "            'spoken',\n",
      "            'in',\n",
      "            'a',\n",
      "            'few',\n",
      "            'remote',\n",
      "            'towns',\n",
      "            'or',\n",
      "            'villages',\n",
      "            'bordering',\n",
      "            'to',\n",
      "            'Luzhou',\n",
      "            ',',\n",
      "            'Leshan',\n",
      "            'and',\n",
      "            'Yibin',\n",
      "            '.']],\n",
      " 'title': 'Zigong dialect',\n",
      " 'vertexSet': [[{'name': 'Zigong City',\n",
      "                 'pos': [10, 12],\n",
      "                 'sent_id': 3,\n",
      "                 'type': 'LOC'},\n",
      "                {'name': 'Zigong City',\n",
      "                 'pos': [8, 10],\n",
      "                 'sent_id': 1,\n",
      "                 'type': 'LOC'},\n",
      "                {'name': 'Zigong',\n",
      "                 'pos': [25, 26],\n",
      "                 'sent_id': 3,\n",
      "                 'type': 'LOC'},\n",
      "                {'name': 'Zigong',\n",
      "                 'pos': [11, 12],\n",
      "                 'sent_id': 1,\n",
      "                 'type': 'LOC'},\n",
      "                {'name': 'Zigong', 'pos': [0, 1], 'sent_id': 0, 'type': 'LOC'},\n",
      "                {'name': 'Zigong', 'pos': [5, 6], 'sent_id': 2, 'type': 'LOC'},\n",
      "                {'name': 'Zigong',\n",
      "                 'pos': [14, 15],\n",
      "                 'sent_id': 0,\n",
      "                 'type': 'LOC'},\n",
      "                {'name': 'Zigong', 'pos': [7, 8], 'sent_id': 2, 'type': 'LOC'}],\n",
      "               [{'name': 'Southwestern Mandarin',\n",
      "                 'pos': [8, 10],\n",
      "                 'sent_id': 0,\n",
      "                 'type': 'MISC'}],\n",
      "               [{'name': 'Fushun',\n",
      "                 'pos': [16, 17],\n",
      "                 'sent_id': 0,\n",
      "                 'type': 'LOC'}],\n",
      "               [{'name': 'Weiyuan',\n",
      "                 'pos': [18, 19],\n",
      "                 'sent_id': 0,\n",
      "                 'type': 'LOC'}],\n",
      "               [{'name': 'Rongxian',\n",
      "                 'pos': [21, 22],\n",
      "                 'sent_id': 0,\n",
      "                 'type': 'LOC'},\n",
      "                {'name': 'Rongxian',\n",
      "                 'pos': [5, 6],\n",
      "                 'sent_id': 3,\n",
      "                 'type': 'LOC'},\n",
      "                {'name': 'Rongxian',\n",
      "                 'pos': [14, 15],\n",
      "                 'sent_id': 1,\n",
      "                 'type': 'LOC'},\n",
      "                {'name': 'Rongxian',\n",
      "                 'pos': [14, 15],\n",
      "                 'sent_id': 3,\n",
      "                 'type': 'LOC'}],\n",
      "               [{'name': 'Yibin', 'pos': [19, 20], 'sent_id': 5, 'type': 'LOC'},\n",
      "                {'name': 'Yibin',\n",
      "                 'pos': [26, 27],\n",
      "                 'sent_id': 0,\n",
      "                 'type': 'LOC'}],\n",
      "               [{'name': 'Neijiang',\n",
      "                 'pos': [28, 29],\n",
      "                 'sent_id': 0,\n",
      "                 'type': 'LOC'}],\n",
      "               [{'name': 'Longchang',\n",
      "                 'pos': [30, 31],\n",
      "                 'sent_id': 0,\n",
      "                 'type': 'LOC'}],\n",
      "               [{'name': 'Sichuan',\n",
      "                 'pos': [36, 37],\n",
      "                 'sent_id': 0,\n",
      "                 'type': 'LOC'}],\n",
      "               [{'name': 'four', 'pos': [2, 3], 'sent_id': 1, 'type': 'NUM'}],\n",
      "               [{'name': 'Chinese',\n",
      "                 'pos': [3, 4],\n",
      "                 'sent_id': 1,\n",
      "                 'type': 'MISC'}],\n",
      "               [{'name': 'Hakka',\n",
      "                 'pos': [17, 18],\n",
      "                 'sent_id': 1,\n",
      "                 'type': 'LOC'}],\n",
      "               [{'name': 'Minjiang',\n",
      "                 'pos': [19, 20],\n",
      "                 'sent_id': 1,\n",
      "                 'type': 'LOC'},\n",
      "                {'name': 'Minjiang',\n",
      "                 'pos': [2, 3],\n",
      "                 'sent_id': 5,\n",
      "                 'type': 'LOC'}],\n",
      "               [{'name': 'Hakka', 'pos': [8, 9], 'sent_id': 4, 'type': 'ORG'},\n",
      "                {'name': 'Hakka',\n",
      "                 'pos': [17, 18],\n",
      "                 'sent_id': 4,\n",
      "                 'type': 'ORG'}],\n",
      "               [{'name': 'Hakka',\n",
      "                 'pos': [26, 27],\n",
      "                 'sent_id': 4,\n",
      "                 'type': 'MISC'}],\n",
      "               [{'name': 'Luzhou',\n",
      "                 'pos': [15, 16],\n",
      "                 'sent_id': 5,\n",
      "                 'type': 'LOC'}],\n",
      "               [{'name': 'Leshan',\n",
      "                 'pos': [17, 18],\n",
      "                 'sent_id': 5,\n",
      "                 'type': 'LOC'}]]}\n",
      "{'labels': [{'evidence': [0], 'h': 6, 'r': 'P131', 't': 8},\n",
      "            {'evidence': [0], 'h': 8, 'r': 'P150', 't': 6},\n",
      "            {'evidence': [0], 'h': 8, 'r': 'P150', 't': 5},\n",
      "            {'evidence': [0], 'h': 8, 'r': 'P150', 't': 0},\n",
      "            {'evidence': [0], 'h': 5, 'r': 'P131', 't': 8},\n",
      "            {'evidence': [0], 'h': 0, 'r': 'P131', 't': 8},\n",
      "            {'evidence': [], 'h': 6, 'r': 'P17', 't': 10},\n",
      "            {'evidence': [], 'h': 2, 'r': 'P131', 't': 8},\n",
      "            {'evidence': [], 'h': 8, 'r': 'P150', 't': 2},\n",
      "            {'evidence': [], 'h': 5, 'r': 'P17', 't': 10},\n",
      "            {'evidence': [], 'h': 1, 'r': 'P279', 't': 10},\n",
      "            {'evidence': [], 'h': 8, 'r': 'P150', 't': 3},\n",
      "            {'evidence': [], 'h': 7, 'r': 'P131', 't': 8},\n",
      "            {'evidence': [], 'h': 8, 'r': 'P150', 't': 7},\n",
      "            {'evidence': [], 'h': 3, 'r': 'P131', 't': 8},\n",
      "            {'evidence': [], 'h': 10, 'r': 'P150', 't': 8},\n",
      "            {'evidence': [], 'h': 4, 'r': 'P131', 't': 0},\n",
      "            {'evidence': [], 'h': 2, 'r': 'P17', 't': 10},\n",
      "            {'evidence': [], 'h': 4, 'r': 'P131', 't': 8}],\n",
      " 'sents': [['Zigong',\n",
      "            'dialect',\n",
      "            '(',\n",
      "            ')',\n",
      "            'is',\n",
      "            'a',\n",
      "            'branch',\n",
      "            'of',\n",
      "            'Southwestern',\n",
      "            'Mandarin',\n",
      "            ',',\n",
      "            'spoken',\n",
      "            'mainly',\n",
      "            'in',\n",
      "            'Zigong',\n",
      "            ',',\n",
      "            'Fushun',\n",
      "            ',',\n",
      "            'Weiyuan',\n",
      "            ',',\n",
      "            'east',\n",
      "            'Rongxian',\n",
      "            'and',\n",
      "            'some',\n",
      "            'parts',\n",
      "            'of',\n",
      "            'Yibin',\n",
      "            ',',\n",
      "            'Neijiang',\n",
      "            ',',\n",
      "            'Longchang',\n",
      "            'and',\n",
      "            'other',\n",
      "            'neighboring',\n",
      "            'areas',\n",
      "            'of',\n",
      "            'Sichuan',\n",
      "            '.'],\n",
      "           ['At',\n",
      "            'least',\n",
      "            'four',\n",
      "            'Chinese',\n",
      "            'dialects',\n",
      "            'are',\n",
      "            'spoken',\n",
      "            'in',\n",
      "            'Zigong',\n",
      "            'City',\n",
      "            ':',\n",
      "            'Zigong',\n",
      "            'dialect',\n",
      "            ',',\n",
      "            'Rongxian',\n",
      "            'dialect',\n",
      "            ',',\n",
      "            'Hakka',\n",
      "            'and',\n",
      "            'Minjiang',\n",
      "            'dialect',\n",
      "            '.'],\n",
      "           ['A',\n",
      "            'majority',\n",
      "            'of',\n",
      "            'people',\n",
      "            'in',\n",
      "            'Zigong',\n",
      "            'speak',\n",
      "            'Zigong',\n",
      "            'dialect',\n",
      "            '.'],\n",
      "           ['However',\n",
      "            ',',\n",
      "            'most',\n",
      "            'people',\n",
      "            'in',\n",
      "            'Rongxian',\n",
      "            ',',\n",
      "            'a',\n",
      "            'county',\n",
      "            'of',\n",
      "            'Zigong',\n",
      "            'City',\n",
      "            ',',\n",
      "            'speak',\n",
      "            'Rongxian',\n",
      "            'dialect',\n",
      "            ',',\n",
      "            'whose',\n",
      "            'pronunciation',\n",
      "            'is',\n",
      "            'quite',\n",
      "            'different',\n",
      "            'from',\n",
      "            'that',\n",
      "            'of',\n",
      "            'Zigong',\n",
      "            'dialect',\n",
      "            '.'],\n",
      "           ['Besides',\n",
      "            ',',\n",
      "            'owing',\n",
      "            'to',\n",
      "            'a',\n",
      "            'great',\n",
      "            'number',\n",
      "            'of',\n",
      "            'Hakka',\n",
      "            'immigrants',\n",
      "            'in',\n",
      "            'history',\n",
      "            ',',\n",
      "            'a',\n",
      "            'small',\n",
      "            'number',\n",
      "            'of',\n",
      "            'Hakka',\n",
      "            'people',\n",
      "            'in',\n",
      "            'certain',\n",
      "            'towns',\n",
      "            'also',\n",
      "            'remain',\n",
      "            'to',\n",
      "            'speak',\n",
      "            'Hakka',\n",
      "            '.'],\n",
      "           ['Also',\n",
      "            ',',\n",
      "            'Minjiang',\n",
      "            'dialect',\n",
      "            'is',\n",
      "            'spoken',\n",
      "            'in',\n",
      "            'a',\n",
      "            'few',\n",
      "            'remote',\n",
      "            'towns',\n",
      "            'or',\n",
      "            'villages',\n",
      "            'bordering',\n",
      "            'to',\n",
      "            'Luzhou',\n",
      "            ',',\n",
      "            'Leshan',\n",
      "            'and',\n",
      "            'Yibin',\n",
      "            '.']],\n",
      " 'title': 'Zigong dialect',\n",
      " 'vertexSet': [[{'global_pos': [80, 80],\n",
      "                 'index': '0_0',\n",
      "                 'name': 'Zigong City',\n",
      "                 'pos': [10, 12],\n",
      "                 'sent_id': 3,\n",
      "                 'type': 'LOC'},\n",
      "                {'global_pos': [46, 46],\n",
      "                 'index': '0_1',\n",
      "                 'name': 'Zigong City',\n",
      "                 'pos': [8, 10],\n",
      "                 'sent_id': 1,\n",
      "                 'type': 'LOC'},\n",
      "                {'global_pos': [95, 95],\n",
      "                 'index': '0_2',\n",
      "                 'name': 'Zigong',\n",
      "                 'pos': [25, 26],\n",
      "                 'sent_id': 3,\n",
      "                 'type': 'LOC'},\n",
      "                {'global_pos': [49, 49],\n",
      "                 'index': '0_3',\n",
      "                 'name': 'Zigong',\n",
      "                 'pos': [11, 12],\n",
      "                 'sent_id': 1,\n",
      "                 'type': 'LOC'},\n",
      "                {'global_pos': [0, 0],\n",
      "                 'index': '0_4',\n",
      "                 'name': 'Zigong',\n",
      "                 'pos': [0, 1],\n",
      "                 'sent_id': 0,\n",
      "                 'type': 'LOC'},\n",
      "                {'global_pos': [65, 65],\n",
      "                 'index': '0_5',\n",
      "                 'name': 'Zigong',\n",
      "                 'pos': [5, 6],\n",
      "                 'sent_id': 2,\n",
      "                 'type': 'LOC'},\n",
      "                {'global_pos': [14, 14],\n",
      "                 'index': '0_6',\n",
      "                 'name': 'Zigong',\n",
      "                 'pos': [14, 15],\n",
      "                 'sent_id': 0,\n",
      "                 'type': 'LOC'},\n",
      "                {'global_pos': [67, 67],\n",
      "                 'index': '0_7',\n",
      "                 'name': 'Zigong',\n",
      "                 'pos': [7, 8],\n",
      "                 'sent_id': 2,\n",
      "                 'type': 'LOC'}],\n",
      "               [{'global_pos': [8, 8],\n",
      "                 'index': '1_0',\n",
      "                 'name': 'Southwestern Mandarin',\n",
      "                 'pos': [8, 10],\n",
      "                 'sent_id': 0,\n",
      "                 'type': 'MISC'}],\n",
      "               [{'global_pos': [16, 16],\n",
      "                 'index': '2_0',\n",
      "                 'name': 'Fushun',\n",
      "                 'pos': [16, 17],\n",
      "                 'sent_id': 0,\n",
      "                 'type': 'LOC'}],\n",
      "               [{'global_pos': [18, 18],\n",
      "                 'index': '3_0',\n",
      "                 'name': 'Weiyuan',\n",
      "                 'pos': [18, 19],\n",
      "                 'sent_id': 0,\n",
      "                 'type': 'LOC'}],\n",
      "               [{'global_pos': [21, 21],\n",
      "                 'index': '4_0',\n",
      "                 'name': 'Rongxian',\n",
      "                 'pos': [21, 22],\n",
      "                 'sent_id': 0,\n",
      "                 'type': 'LOC'},\n",
      "                {'global_pos': [75, 75],\n",
      "                 'index': '4_1',\n",
      "                 'name': 'Rongxian',\n",
      "                 'pos': [5, 6],\n",
      "                 'sent_id': 3,\n",
      "                 'type': 'LOC'},\n",
      "                {'global_pos': [52, 52],\n",
      "                 'index': '4_2',\n",
      "                 'name': 'Rongxian',\n",
      "                 'pos': [14, 15],\n",
      "                 'sent_id': 1,\n",
      "                 'type': 'LOC'},\n",
      "                {'global_pos': [84, 84],\n",
      "                 'index': '4_3',\n",
      "                 'name': 'Rongxian',\n",
      "                 'pos': [14, 15],\n",
      "                 'sent_id': 3,\n",
      "                 'type': 'LOC'}],\n",
      "               [{'global_pos': [145, 145],\n",
      "                 'index': '5_0',\n",
      "                 'name': 'Yibin',\n",
      "                 'pos': [19, 20],\n",
      "                 'sent_id': 5,\n",
      "                 'type': 'LOC'},\n",
      "                {'global_pos': [26, 26],\n",
      "                 'index': '5_1',\n",
      "                 'name': 'Yibin',\n",
      "                 'pos': [26, 27],\n",
      "                 'sent_id': 0,\n",
      "                 'type': 'LOC'}],\n",
      "               [{'global_pos': [28, 28],\n",
      "                 'index': '6_0',\n",
      "                 'name': 'Neijiang',\n",
      "                 'pos': [28, 29],\n",
      "                 'sent_id': 0,\n",
      "                 'type': 'LOC'}],\n",
      "               [{'global_pos': [30, 30],\n",
      "                 'index': '7_0',\n",
      "                 'name': 'Longchang',\n",
      "                 'pos': [30, 31],\n",
      "                 'sent_id': 0,\n",
      "                 'type': 'LOC'}],\n",
      "               [{'global_pos': [36, 36],\n",
      "                 'index': '8_0',\n",
      "                 'name': 'Sichuan',\n",
      "                 'pos': [36, 37],\n",
      "                 'sent_id': 0,\n",
      "                 'type': 'LOC'}],\n",
      "               [{'global_pos': [40, 40],\n",
      "                 'index': '9_0',\n",
      "                 'name': 'four',\n",
      "                 'pos': [2, 3],\n",
      "                 'sent_id': 1,\n",
      "                 'type': 'NUM'}],\n",
      "               [{'global_pos': [41, 41],\n",
      "                 'index': '10_0',\n",
      "                 'name': 'Chinese',\n",
      "                 'pos': [3, 4],\n",
      "                 'sent_id': 1,\n",
      "                 'type': 'MISC'}],\n",
      "               [{'global_pos': [55, 55],\n",
      "                 'index': '11_0',\n",
      "                 'name': 'Hakka',\n",
      "                 'pos': [17, 18],\n",
      "                 'sent_id': 1,\n",
      "                 'type': 'LOC'}],\n",
      "               [{'global_pos': [57, 57],\n",
      "                 'index': '12_0',\n",
      "                 'name': 'Minjiang',\n",
      "                 'pos': [19, 20],\n",
      "                 'sent_id': 1,\n",
      "                 'type': 'LOC'},\n",
      "                {'global_pos': [128, 128],\n",
      "                 'index': '12_1',\n",
      "                 'name': 'Minjiang',\n",
      "                 'pos': [2, 3],\n",
      "                 'sent_id': 5,\n",
      "                 'type': 'LOC'}],\n",
      "               [{'global_pos': [106, 106],\n",
      "                 'index': '13_0',\n",
      "                 'name': 'Hakka',\n",
      "                 'pos': [8, 9],\n",
      "                 'sent_id': 4,\n",
      "                 'type': 'ORG'},\n",
      "                {'global_pos': [115, 115],\n",
      "                 'index': '13_1',\n",
      "                 'name': 'Hakka',\n",
      "                 'pos': [17, 18],\n",
      "                 'sent_id': 4,\n",
      "                 'type': 'ORG'}],\n",
      "               [{'global_pos': [124, 124],\n",
      "                 'index': '14_0',\n",
      "                 'name': 'Hakka',\n",
      "                 'pos': [26, 27],\n",
      "                 'sent_id': 4,\n",
      "                 'type': 'MISC'}],\n",
      "               [{'global_pos': [141, 141],\n",
      "                 'index': '15_0',\n",
      "                 'name': 'Luzhou',\n",
      "                 'pos': [15, 16],\n",
      "                 'sent_id': 5,\n",
      "                 'type': 'LOC'}],\n",
      "               [{'global_pos': [143, 143],\n",
      "                 'index': '16_0',\n",
      "                 'name': 'Leshan',\n",
      "                 'pos': [17, 18],\n",
      "                 'sent_id': 5,\n",
      "                 'type': 'LOC'}]]}\n"
     ]
    }
   ],
   "source": [
    "pprint(docred[120])\n",
    "pprint(redocred[120])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cf8aa6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: DocRED\n",
      "Total documents: 3053\n",
      "Total unique entities: 59493\n",
      "Total annotated relations: 38180\n",
      "Top 5 frequent relations:\n",
      "  P17: 8921\n",
      "  P131: 4193\n",
      "  P27: 2689\n",
      "  P150: 2004\n",
      "  P577: 1142\n",
      "Dataset: Re-DocRED\n",
      "Total documents: 3053\n",
      "Total unique entities: 59359\n",
      "Total annotated relations: 85932\n",
      "Top 5 frequent relations:\n",
      "  P131: 20402\n",
      "  P17: 14401\n",
      "  P27: 4665\n",
      "  P150: 3369\n",
      "  P800: 3055\n"
     ]
    }
   ],
   "source": [
    "def basic_stats(dataset, name=\"\"):\n",
    "    print(f\"Dataset: {name}\")\n",
    "    print(\"Total documents:\", len(dataset))\n",
    "    \n",
    "    total_entities = sum(len(d['vertexSet']) for d in dataset)\n",
    "    print(\"Total unique entities:\", total_entities)\n",
    "    \n",
    "    total_rels = sum(len(d.get('labels', [])) for d in dataset)\n",
    "    print(\"Total annotated relations:\", total_rels)\n",
    "\n",
    "    rel_dist = {}\n",
    "    for d in dataset:\n",
    "        for rel in d.get('labels', []):\n",
    "            rel_type = rel['r']\n",
    "            rel_dist[rel_type] = rel_dist.get(rel_type, 0) + 1\n",
    "\n",
    "    print(\"Top 5 frequent relations:\")\n",
    "    for rel, count in sorted(rel_dist.items(), key=lambda x: -x[1])[:5]:\n",
    "        print(f\"  {rel}: {count}\")\n",
    "\n",
    "basic_stats(docred, \"DocRED\")\n",
    "basic_stats(redocred, \"Re-DocRED\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84c18016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-sentence: 6420 (16.82%)\n",
      "Intra-sentence: 31760 (83.18%)\n",
      "Cross-sentence: 16158 (18.80%)\n",
      "Intra-sentence: 69774 (81.20%)\n"
     ]
    }
   ],
   "source": [
    "def cross_sentence_stats(dataset):\n",
    "    cross = 0\n",
    "    intra = 0\n",
    "    for doc in dataset:\n",
    "        sentences = doc['sents']\n",
    "        sent_map = {}  # map token index to sentence id\n",
    "        idx = 0\n",
    "        for i, sent in enumerate(sentences):\n",
    "            for _ in sent:\n",
    "                sent_map[idx] = i\n",
    "                idx += 1\n",
    "\n",
    "        for rel in doc.get('labels', []):\n",
    "            h_mention = doc['vertexSet'][rel['h']][0]\n",
    "            t_mention = doc['vertexSet'][rel['t']][0]\n",
    "            h_sent = sent_map[h_mention['pos'][0]]\n",
    "            t_sent = sent_map[t_mention['pos'][0]]\n",
    "            if h_sent == t_sent:\n",
    "                intra += 1\n",
    "            else:\n",
    "                cross += 1\n",
    "    total = cross + intra\n",
    "    print(f\"Cross-sentence: {cross} ({cross/total:.2%})\")\n",
    "    print(f\"Intra-sentence: {intra} ({intra/total:.2%})\")\n",
    "\n",
    "cross_sentence_stats(docred)\n",
    "cross_sentence_stats(redocred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc3dea58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents with different labels between DocRED and Re-DocRED: 3025\n"
     ]
    }
   ],
   "source": [
    "def compare_relation_counts(docred, redocred):\n",
    "    redocred_map = {d['title']: d for d in redocred if 'title' in d}\n",
    "    mismatch_count = 0\n",
    "\n",
    "    for d in docred:\n",
    "        title = d.get('title', None)\n",
    "        if title and title in redocred_map:\n",
    "            rel1 = {(r['h'], r['t'], r['r']) for r in d.get('labels', [])}\n",
    "            rel2 = {(r['h'], r['t'], r['r']) for r in redocred_map[title].get('labels', [])}\n",
    "            if rel1 != rel2:\n",
    "                mismatch_count += 1\n",
    "\n",
    "    print(f\"Documents with different labels between DocRED and Re-DocRED: {mismatch_count}\")\n",
    "\n",
    "compare_relation_counts(docred, redocred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "894ebf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_label(mylabel,data_name):   \n",
    "    na_count = 0\n",
    "    golden_count = 0\n",
    "    rel_counter = Counter()\n",
    "    \n",
    "    for doc in data_name:\n",
    "        labels = doc.get(\"labels\", []) + doc.get(\"labels2_annotator_id\", [])\n",
    "        for label in labels:\n",
    "            r = label[\"r\"]\n",
    "            if r == mylabel:\n",
    "                na_count += 1\n",
    "            else:\n",
    "                golden_count += 1\n",
    "            rel_counter[r] += 1\n",
    "            \n",
    "    print(f\"Total positive (golden) labels: {golden_count}\")\n",
    "    print(f\"Total NA labels: {na_count}\")\n",
    "    print(f\"Ratio NA : Golden = {na_count} : {golden_count} = {na_count / golden_count:.2f}\")\n",
    "\n",
    "    print(\"\\nTop 10 relations:\")\n",
    "    for r, c in rel_counter.most_common(10):\n",
    "        print(f\"{r:10} : {c}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bfe3ab35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total positive (golden) labels: 29259\n",
      "Total NA labels: 8921\n",
      "Ratio NA : Golden = 8921 : 29259 = 0.30\n",
      "\n",
      "Top 10 relations:\n",
      "P17        : 8921\n",
      "P131       : 4193\n",
      "P27        : 2689\n",
      "P150       : 2004\n",
      "P577       : 1142\n",
      "P175       : 1052\n",
      "P569       : 1044\n",
      "P570       : 805\n",
      "P527       : 632\n",
      "P161       : 621\n"
     ]
    }
   ],
   "source": [
    "#test the function\n",
    "find_label(test_label,docred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc1ec7c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total positive (golden) labels: 38180\n",
      "Total NA labels: 0\n",
      "Ratio NA : Golden = 0 : 38180 = 0.00\n",
      "\n",
      "Top 10 relations:\n",
      "P17        : 8921\n",
      "P131       : 4193\n",
      "P27        : 2689\n",
      "P150       : 2004\n",
      "P577       : 1142\n",
      "P175       : 1052\n",
      "P569       : 1044\n",
      "P570       : 805\n",
      "P527       : 632\n",
      "P161       : 621\n"
     ]
    }
   ],
   "source": [
    "#this is only for checking to see if any na sample available\n",
    "#normally only positive relations are saved.\n",
    "#na relations are implicit soit is normal to get zero for negatives\n",
    "find_label(na_label,docred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21aed611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total positive (golden) labels: 85932\n",
      "Total NA labels: 0\n",
      "Ratio NA : Golden = 0 : 85932 = 0.00\n",
      "\n",
      "Top 10 relations:\n",
      "P131       : 20402\n",
      "P17        : 14401\n",
      "P27        : 4665\n",
      "P150       : 3369\n",
      "P800       : 3055\n",
      "P527       : 2313\n",
      "P361       : 2112\n",
      "P175       : 1773\n",
      "P577       : 1621\n",
      "P463       : 1299\n"
     ]
    }
   ],
   "source": [
    " find_label(na_label,redocred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f08b714",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_possible_pair(data_name):\n",
    "    total_pairs = 0\n",
    "    positive_pairs = 0\n",
    "\n",
    "    for doc in data_name:\n",
    "        num_entities = len(doc[\"vertexSet\"])\n",
    "        all_pairs = set((h, t) for h in range(num_entities) for t in range(num_entities) if h != t)\n",
    "\n",
    "        # Get positive pairs from labels and labels2_annotator_id\n",
    "        raw_labels = doc.get(\"labels\", []) + doc.get(\"labels2_annotator_id\", [])\n",
    "        pos_pairs = set((label[\"h\"], label[\"t\"]) for label in raw_labels)\n",
    "\n",
    "        total_pairs += len(all_pairs)\n",
    "        positive_pairs += len(pos_pairs)\n",
    "\n",
    "    print(f\"Total entity pairs: {total_pairs}\")\n",
    "    print(f\"Positive pairs (golden labels): {positive_pairs}\")\n",
    "    print(f\"Negative pairs (NA): {total_pairs - positive_pairs}\")\n",
    "    print(f\"Ratio (neg/pos): {(total_pairs - positive_pairs) / positive_pairs:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7abca599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total entity pairs: 1198650\n",
      "Positive pairs (golden labels): 35615\n",
      "Negative pairs (NA): 1163035\n",
      "Ratio (neg/pos): 32.66\n"
     ]
    }
   ],
   "source": [
    "find_possible_pair(docred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5c4fe04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total entity pairs: 1193092\n",
      "Positive pairs (golden labels): 67808\n",
      "Negative pairs (NA): 1125284\n",
      "Ratio (neg/pos): 16.60\n"
     ]
    }
   ],
   "source": [
    "find_possible_pair(redocred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f06ed8a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'evidence': [0], 'h': 4, 'r': 'P35', 't': 5},\n",
      " {'evidence': [0, 1, 2], 'h': 5, 'r': 'P26', 't': 3},\n",
      " {'evidence': [2], 'h': 5, 'r': 'P140', 't': 8},\n",
      " {'evidence': [0, 1, 2], 'h': 5, 'r': 'P27', 't': 1},\n",
      " {'evidence': [0, 1, 2], 'h': 3, 'r': 'P27', 't': 4},\n",
      " {'evidence': [0, 1, 2], 'h': 3, 'r': 'P26', 't': 5},\n",
      " {'evidence': [2], 'h': 3, 'r': 'P140', 't': 8},\n",
      " {'evidence': [0, 1, 2], 'h': 3, 'r': 'P27', 't': 1},\n",
      " {'evidence': [0], 'h': 0, 'r': 'P577', 't': 2},\n",
      " {'evidence': [2], 'h': 7, 'r': 'P1001', 't': 4},\n",
      " {'evidence': [2], 'h': 7, 'r': 'P577', 't': 2},\n",
      " {'evidence': [2], 'h': 7, 'r': 'P1001', 't': 1},\n",
      " {'evidence': [0], 'h': 5, 'r': 'P27', 't': 4}]\n",
      "----------------------\n",
      "[{'evidence': [0], 'h': 4, 'r': 'P35', 't': 5},\n",
      " {'evidence': [0, 1, 2], 'h': 5, 'r': 'P26', 't': 3},\n",
      " {'evidence': [2], 'h': 5, 'r': 'P140', 't': 8},\n",
      " {'evidence': [0, 1, 2], 'h': 5, 'r': 'P27', 't': 1},\n",
      " {'evidence': [0, 1, 2], 'h': 3, 'r': 'P27', 't': 4},\n",
      " {'evidence': [0, 1, 2], 'h': 3, 'r': 'P26', 't': 5},\n",
      " {'evidence': [2], 'h': 3, 'r': 'P140', 't': 8},\n",
      " {'evidence': [0, 1, 2], 'h': 3, 'r': 'P27', 't': 1},\n",
      " {'evidence': [0], 'h': 0, 'r': 'P577', 't': 2},\n",
      " {'evidence': [2], 'h': 7, 'r': 'P1001', 't': 4},\n",
      " {'evidence': [2], 'h': 7, 'r': 'P577', 't': 2},\n",
      " {'evidence': [2], 'h': 7, 'r': 'P1001', 't': 1},\n",
      " {'evidence': [0], 'h': 5, 'r': 'P27', 't': 4},\n",
      " {'evidence': [], 'h': 4, 'r': 'P194', 't': 6},\n",
      " {'evidence': [], 'h': 7, 'r': 'P585', 't': 2},\n",
      " {'evidence': [0], 'h': 5, 'r': 'P1001', 't': 4},\n",
      " {'evidence': [], 'h': 6, 'r': 'P1001', 't': 4}]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "testnumber=780\n",
    "pprint(docred[testnumber]['labels'])\n",
    "print('----------------------')\n",
    "pprint(redocred[testnumber]['labels'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e020ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_key(sample):\n",
    "    rels = {(r[\"h\"], r[\"t\"]) for r in sample.get(\"labels\", [])}\n",
    "    return sample[\"title\"], frozenset(rels)\n",
    "\n",
    "# First, index DocRED\n",
    "unique = {}\n",
    "for sample in docred:\n",
    "    key = sample[\"title\"]\n",
    "    unique[key] = sample\n",
    "\n",
    "# Then overwrite with Re-DocRED if duplicate title exists\n",
    "for sample in redocred:\n",
    "    key = sample[\"title\"]\n",
    "    unique[key] = sample  # this will overwrite DocRED version\n",
    "\n",
    "merged_data = list(unique.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e5833987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'r': 'P35', 'h': 4, 't': 5, 'evidence': [0]},\n",
       " {'r': 'P26', 'h': 5, 't': 3, 'evidence': [0, 1, 2]},\n",
       " {'r': 'P140', 'h': 5, 't': 8, 'evidence': [2]},\n",
       " {'r': 'P27', 'h': 5, 't': 1, 'evidence': [0, 1, 2]},\n",
       " {'r': 'P27', 'h': 3, 't': 4, 'evidence': [0, 1, 2]},\n",
       " {'r': 'P26', 'h': 3, 't': 5, 'evidence': [0, 1, 2]},\n",
       " {'r': 'P140', 'h': 3, 't': 8, 'evidence': [2]},\n",
       " {'r': 'P27', 'h': 3, 't': 1, 'evidence': [0, 1, 2]},\n",
       " {'r': 'P577', 'h': 0, 't': 2, 'evidence': [0]},\n",
       " {'r': 'P1001', 'h': 7, 't': 4, 'evidence': [2]},\n",
       " {'r': 'P577', 'h': 7, 't': 2, 'evidence': [2]},\n",
       " {'r': 'P1001', 'h': 7, 't': 1, 'evidence': [2]},\n",
       " {'r': 'P27', 'h': 5, 't': 4, 'evidence': [0]},\n",
       " {'h': 4, 't': 6, 'r': 'P194', 'evidence': []},\n",
       " {'h': 7, 't': 2, 'r': 'P585', 'evidence': []},\n",
       " {'h': 5, 't': 4, 'r': 'P1001', 'evidence': [0]},\n",
       " {'h': 6, 't': 4, 'r': 'P1001', 'evidence': []}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data[testnumber]['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a791e9ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
